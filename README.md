# ðŸ¤– Neuropuppet: AI-Controlled Marionette Puppet

> "Where strings meet sentience."

---

## ðŸŽ¯ Overview

**Neuropuppet** is a working prototype that merges robotics, machine vision, and AI to control a humanoid marionette puppet. Using stepper motors to pull strings, the puppet learns through feedback to wave, walk, and perform gestures using reinforcement or imitation learning.

This project is a living intersection of mechanical puppetry, stepper control, and self-learning AI.

---

## ðŸ› ï¸ Hardware Overview

| Component | Description | Est. Cost (USD) |
|----------|-------------|----------------:|
| **6x NEMA 17 Steppers** | Pull puppet strings via spools | ~$10â€“$15 each |
| **6x Pololu A4988 Drivers** | Microstepping motor drivers | ~$7â€“$10 each |
| **Arduino Mega** | Controls motors with step/direction signals | ~$30 |
| **Raspberry Pi 4** | Runs vision & AI logic | ~$45â€“$55 |
| **USB/Pi Camera** | Tracks puppetâ€™s pose | ~$20â€“$30 |
| **Puppet (30â€“50 cm)** | Custom or store-bought with jointed limbs | ~$20â€“$50 |
| **Motor Frame + Rigging** | Supports motors and guides strings | ~$30 |
| **Power Supply (12V, 10A)** | Runs steppers | ~$25 |

**Total Est.:** ~$250â€“$350

---

## ðŸ§µ Mechanical Rigging

- **Top bar with mounted motors**
- Strings route vertically from each motor through pulleys
- Strings attach to: head, hands, and feet
- Nylon fishing line preferred
- All motors use same spool size for uniformity

**Degrees of Freedom:**
- Head (1), Arms (2), Legs (2), Torso (optional)

---

## âš¡ Electronics Summary

- Step/Dir signals per motor via Arduino
- A4988 drivers with 1/16 microstepping
- 12V 6â€“10A PSU with proper decoupling caps
- Serial communication with Pi (via `pyserial`)
- Optional: Limit switches or encoder marks for homing

---

## ðŸ§  Software Architecture

Written in Python (venv + pip). Main components:

```
â”œâ”€â”€ arduino/motor_control.ino        # Stepper control firmware
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ vision.py                    # OpenCV or MediaPipe tracking
â”‚   â”œâ”€â”€ control.py                   # Sends motor commands to Arduino
â”‚   â”œâ”€â”€ rl_agent.py                  # AI learning agent
â”‚   â””â”€â”€ utils.py                     # Config, logging, tools
â”œâ”€â”€ main.py                          # Training/control loop entry
```

**Dependencies:**
```bash
opencv-python
mediapipe
pyserial
torch or tensorflow
stable-baselines3 (for RL)
```

---

## ðŸ§  AI Motion Learning

Neuropuppet supports:

### ðŸŸ¡ Reinforcement Learning
- **State:** 2D positions of hands, feet, head from vision
- **Action:** Relative movement of each motor (e.g. Î´1 to Î´6)
- **Reward:** Pose accuracy, smoothness, or musical timing
- **Frameworks:** PyTorch + Stable Baselines3 (PPO or DDPG)

### ðŸŸ£ Imitation Learning
- Human performs motion â†’ AI learns via captured vision
- Train a model to mimic action sequences from video

---

## ðŸ“¹ Vision Feedback

- **MediaPipe Pose** or color markers
- Extract keypoint coordinates (e.g. hands, feet)
- Normalize frame size, smooth over time
- Use as RL state or imitation reference

---

## ðŸ§ª Testing & Calibration

- Manual homing or switch-based homing
- Start with scripted sequences
- Log motion outcomes vs vision
- Refine motor steps per string movement empirically

---

## ðŸ§¯ Safety Notes

- Clamp motion range
- Watch for string tangles
- Always have a physical kill switch for 12V line
- Use acceleration profiles (via AccelStepper)

---

## ðŸŒŒ Future Plans

- Audio-driven dancing (beat â†’ motion)
- 3D pose tracking with stereo camera
- Web dashboard for choreography
- Emotion-driven movement (pose + face sync)

---

## ðŸ”— Inspiration & References

- [Groovinâ€™ Grover â€“ Servo Marionette (Instructables)](http://www.instructables.com/id/Groovin-Grover-A-Microcontroller-based-Marionett/)
- [PuppetMaster â€“ ETH ZÃ¼rich](https://spectrum.ieee.org/eth-surich-puppetmaster-robot)
- [ROMS â€“ NTU Singapore Robotic Marionette](https://mrl.cs.nyu.edu/~perlin/courses/spring2006/class-0424/04-c-hmm-puppet-d[1].pdf)
- [Stepper Motor Control â€“ Pololu A4988 Guide](https://www.pololu.com/product/1182)
- [Vision Tracking â€“ MediaPipe](https://developers.google.com/mediapipe)

---

Â© 2025 Neuropuppet. MIT Licensed. Contributions welcome!

> Pull the strings â€” or let the puppet pull you.
